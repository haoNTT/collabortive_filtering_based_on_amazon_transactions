{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question\n",
    "Create Databases\n",
    "\n",
    "Create the following databases (in a dataframe or HDF5 format) for each of the product categories Electronics, Movies and TV, Clothing Shoes and Jewelry, Cellphones and Accessories, Tools and Home Improvement, Beauty, and Baby:\n",
    "* df_reviews_categoryname: whose columns are timestamp, productid, reviewerid, rating, review_text, review_summary\n",
    "* df_products: whose columns are productid, title, imUrl, brand\n",
    "* df_products_also_bought: indexed productid, contains also_bought column\n",
    "* df_products_also_viewed: indexed productid, contains also_viewed column\n",
    "* df_products_bought_together: indexed productid, contains bought_together column\n",
    "* df_products_sales_rank: indexed by productid contains sales_rank\n",
    "* df_products_categories: indexed by productid contains categories column\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aproach\n",
    "\n",
    "This script reads the reviews data and meta data by category and writes out hdf5 databases for each category with above dataframes as keys.\n",
    "\n",
    "### Read (input) data location\n",
    "* All data being read in for this file has been downloaded from here: http://jmcauley.ucsd.edu/data/amazon/\n",
    "* Two types of data are read in for the categories described above\n",
    " * **reviews data** (downloaded the '5-core' files from the files section)\n",
    " * **meta data** (taken from the pre-category files section)\n",
    "* The data are downloaded locally to the following folders, respectively\n",
    " > home/data_in/reviews_5core\n",
    " \n",
    " > home/data_in/meta_data\n",
    "\n",
    "### Output data location\n",
    "* All data is being written out to the folder\n",
    "> home/data_out/databases/\n",
    "\n",
    "### Output data format\n",
    "* Data is being written out into hdf5 databases for each category.\n",
    "* For example, baby.h5 contains the following keys as dataframes: df_reviews_categoryname, df_products, df_products_also_bought, df_products_also_viewed, df_products_bought_together, df_products_sales_rank and df_products_categories\n",
    "\n",
    "### Process\n",
    "* Each data frame asked for in the question is processed for all categories in a loop.\n",
    "* I have defined functions for most processes.\n",
    "\n",
    "### Some important notes\n",
    "* df_products_also_bought, df_products_also_viewed, df_products_bought_together \n",
    " * These have two columns each, productid and the list of productids associated. \n",
    " * however, the second column is not a list, but a string. This string when being used needs to be split on ' ' to create a list. This was done for faster writing so pytables wouldn't pickle the columns. \n",
    "* productid = asin ( as found in reviews and metadata files)\n",
    "\n",
    "### Time taken to run script\n",
    "approx. 1 hr 15 mins to run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import glob\n",
    "import timeit\n",
    "import feather\n",
    "import os\n",
    "import shutil\n",
    "import numpy as np\n",
    "import time\n",
    "# from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SCRIPT VARIABLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = True\n",
    "\n",
    "refresh_all = True\n",
    "df_reviews_categoryname_status = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SCRIPT FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################\n",
    "# SCRIPT FUNCTIONS #\n",
    "####################\n",
    "\n",
    "def parse(path):\n",
    "    \"\"\"\n",
    "    This functions takes in a json file path \n",
    "    and reads it line by line as an actual\n",
    "    because the lines are not real json \n",
    "    strings\n",
    "    \"\"\"\n",
    "    g = gzip.open(path, 'rb')\n",
    "    for l in g:\n",
    "        yield eval(l)\n",
    "\n",
    "def getDF(path):\n",
    "    \"\"\"\n",
    "    input: path of a json file\n",
    "    output: pd dataframe from json file\n",
    "    \"\"\"\n",
    "    i = 0\n",
    "    df = {}\n",
    "    for d in parse(path):\n",
    "        df[i] = d\n",
    "        i += 1\n",
    "    df_out = pd.DataFrame.from_dict(df, orient='index')\n",
    "    return(df_out)\n",
    "\n",
    "def refresh_directory(dir_path):\n",
    "    if os.path.exists(dir_path):\n",
    "        shutil.rmtree(dir_path)\n",
    "    os.makedirs(dir_path)\n",
    "    \n",
    "\n",
    "##############################################\n",
    "# FUNCTIONS USED IN PROCESSING REVIEWS FILES #\n",
    "##############################################\n",
    "\n",
    "def get_category(in_filename):\n",
    "    \"\"\"\n",
    "    This function extracts the category name from the reviews file name\n",
    "    input: reviews file name\n",
    "    output: category string lower cased \n",
    "    \"\"\"\n",
    "    return (in_filename.split('/reviews_5core/reviews_')[1].split('_5.json.gz')[0].lower())\n",
    "\n",
    "\n",
    "def get_df_reviews_categoryname(df):\n",
    "    \"\"\"\n",
    "    This function creates the df_reviews_categoryname dataframe\n",
    "    input: reviews data for a category, as a pd dataframe as read from json file\n",
    "    output: dataframe with columns timestamp, productid, reviewerid, rating, review_text and review_summary\n",
    "    \"\"\"\n",
    "    df_select = df[['unixReviewTime','asin','reviewerID','overall','reviewText','summary']]\n",
    "    df_select.columns = ['timestamp', 'productid', 'reviewerid', 'rating', 'review_text', 'review_summary']\n",
    "    df_null_asins_removed = df_select.dropna(axis=0, subset=['productid'])\n",
    "    df_nulls_asins_removed_deduped = df_null_asins_removed.drop_duplicates(keep='first').reset_index(drop=True)\n",
    "    return(df_null_asins_removed)\n",
    "\n",
    "\n",
    "###############################################\n",
    "# FUNCTIONS USED IN PROCESSING METADATA FILES #\n",
    "###############################################\n",
    "\n",
    "def get_category_from_metadata(in_filename):\n",
    "    \"\"\"\n",
    "    This function extracts the category name from the metadata file name\n",
    "    input: metadata file name\n",
    "    output: category string lower cased \n",
    "    \"\"\"\n",
    "    return (in_filename.split('/meta_data/meta_')[1].split('.json.gz')[0].lower())\n",
    "\n",
    "def get_df_from_metadata(df, columns_to_select, new_column_names):\n",
    "    \"\"\"\n",
    "    This function simply selects target columns from a meta data pd dataframe and renames them\n",
    "    input: meta data for a category, as a pd dataframe as read from json file\n",
    "    output: dataframe with columns renamed by new_column_names\n",
    "    \"\"\"\n",
    "    df_select = df[columns_to_select]\n",
    "    df_select.columns = new_column_names\n",
    "    df_null_asins_removed = df_select.dropna(axis=0, subset=['productid'])\n",
    "    df_all_nulls_removed = df_select.dropna(axis=0,how='all').reset_index(drop=True)\n",
    "    return(df_all_nulls_removed)\n",
    "\n",
    "def get_dict_embeded_items(df,target_var, target_key):\n",
    "    \"\"\"\n",
    "    This function takes a metadata pd dataframe with a column which contains dictionaries as values\n",
    "    and filters out rows with desired keys only. It then converts the output\n",
    "    to a dataframe \n",
    "    \n",
    "    inputs: target dataframe, target var containing dict, target key to be pulled out\n",
    "    outputs: a dataframe with columns product id, target key. \n",
    "    row output: \n",
    "        productid: productid value.\n",
    "        target_key: a string of associated productids separated by spaces\n",
    "    \"\"\"\n",
    "    asin_list= []\n",
    "    target_list = []\n",
    "    # loop through each row of the data frame\n",
    "    for i in range(df.shape[0]):\n",
    "        asin_value = df.loc[i,'asin'] # extract asin value from row\n",
    "        target_dict = df.loc[i,target_var] # extract the dictionary from row\n",
    "        if target_dict is np.nan:\n",
    "            continue\n",
    "        if target_key in target_dict:\n",
    "            target_key_value = target_dict[target_key] # if the target key is in the dictionary, save\n",
    "        else:\n",
    "            target_key_value = np.nan\n",
    "        asin_list.append(asin_value) # append values to list\n",
    "        target_list.append(target_key_value) # append values to list\n",
    "    df = pd.DataFrame({'productid':asin_list, target_key:target_list}) # convert to dataframe\n",
    "    df.loc[:,target_key] = df[target_key].apply(lambda L: \" \".join(str(x) for x in L) if L is not np.nan else L)\n",
    "    df_nona= df.dropna(axis=0,how='any').reset_index(drop=True) # drop na rows\n",
    "    return(df_nona)\n",
    "\n",
    "\n",
    "def get_df_products_salesrank(df):\n",
    "    \"\"\"\n",
    "    This function creates the df_products_salesrank dataframe. \n",
    "    input: metadata pd dataframe\n",
    "    output: productid, categories = category of rank, salesRank = rank in category for productid\n",
    "    \n",
    "    process: the salesRank is a dictionary of category and rank. \n",
    "    The function explodes that dictionary into two columns of key and value\n",
    "    \"\"\"\n",
    "    asin_list= []\n",
    "    key_list = []\n",
    "    value_list = []\n",
    "    for i in range(df.shape[0]): # loop through each row of the dataframe\n",
    "        asin_value = df.loc[i,'asin']\n",
    "        target_dict = df.loc[i,'salesRank']\n",
    "        if type(target_dict)==float: \n",
    "            continue # if it is a nan value, move to next loop\n",
    "        for key in target_dict.keys():\n",
    "            asin_list.append(asin_value) # add asin value to list\n",
    "            key_list.append(key) # add key of the dictionary (category) to list\n",
    "            value_list.append(target_dict[key]) # add the rank value to the list\n",
    "    df = pd.DataFrame({'productid':asin_list, 'categories':key_list,'salesRank':value_list})\n",
    "    df_nona= df.dropna(axis=0,how='any').reset_index(drop=True) # dropna\n",
    "    return(df_nona)\n",
    "\n",
    "\n",
    "def get_df_products_categories(df):\n",
    "    \"\"\"\n",
    "    This function creates the df_products_categories dataframe\n",
    "    input: metadata pd dataframe\n",
    "    output: productid = asin values, categories = list of all categeries the asin belongs to\n",
    "    process: the categories were lists of lists, this function creates a unique list for each asin\n",
    "    \"\"\"\n",
    "    df_select = df[['asin','categories']]\n",
    "    df_select.loc[:,'categories1'] = df_select.categories.apply(lambda l: list(set([item for sublist in l for item in sublist])))\n",
    "    df_final =  df_select.drop(axis=1,columns=['categories'])\n",
    "    df_final.columns = ['productid','categories']\n",
    "    df_nona = df_final.dropna(axis=0,how='any').reset_index(drop=True)\n",
    "    return(df_nona)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# REMOVE ALL VARIABLES\n",
    "if refresh_all:\n",
    "    refresh_directory('./data_out/databases/')\n",
    "\n",
    "reviews_files_to_read = glob.glob('./data_in/reviews_5core/*.json.gz')\n",
    "metadata_files_to_read = glob.glob('./data_in/meta_data/*.json.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) df_reviews_categoryname by category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/reviews_5core/reviews_Cell_Phones_and_Accessories_5.json.gz\n",
      "(194439, 6)\n",
      "Time:  12.418528391004656\n",
      "\n",
      "\n",
      "./data_in/reviews_5core/reviews_Clothing_Shoes_and_Jewelry_5.json.gz\n",
      "(278677, 6)\n",
      "Time:  13.190927680996538\n",
      "\n",
      "\n",
      "./data_in/reviews_5core/reviews_Electronics_5.json.gz\n",
      "(1689188, 6)\n",
      "Time:  96.25478842499433\n",
      "\n",
      "\n",
      "./data_in/reviews_5core/reviews_Baby_5.json.gz\n",
      "(160792, 6)\n",
      "Time:  9.142972869994992\n",
      "\n",
      "\n",
      "./data_in/reviews_5core/reviews_Tools_and_Home_Improvement_5.json.gz\n",
      "(134476, 6)\n",
      "Time:  7.274447283998597\n",
      "\n",
      "\n",
      "./data_in/reviews_5core/reviews_Movies_and_TV_5.json.gz\n",
      "(1697533, 6)\n",
      "Time:  109.55919255800109\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for filename in reviews_files_to_read:\n",
    "    # start timer\n",
    "    start = timeit.default_timer() \n",
    "    \n",
    "    # get data\n",
    "    categoryname = get_category(filename)\n",
    "    df_transformed = get_df_reviews_categoryname(df=getDF(filename))\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= 'df_reviews_categoryname', mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # end timer\n",
    "    stop = timeit.default_timer() \n",
    "    \n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) df_products"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanwal/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['productid', 'title', 'imUrl', 'brand']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(208321, 4)\n",
      "Time:  23.62301140600175\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(498196, 4)\n",
      "Time:  48.20840496199526\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(259204, 4)\n",
      "Time:  32.33594568300032\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(269120, 4)\n",
      "Time:  27.00891852100176\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(71317, 4)\n",
      "Time:  9.63094223900407\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(346793, 4)\n",
      "Time:  30.400116568998783\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(1503384, 4)\n",
      "Time:  182.36835953399714\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "columns_to_select_ = ['asin','title','imUrl','brand']\n",
    "new_column_names_ = ['productid','title','imUrl','brand']\n",
    "key_ = 'df_products'\n",
    "\n",
    "for filename in metadata_files_to_read:\n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df_transformed = get_df_from_metadata(df=getDF(filename), columns_to_select = columns_to_select_, new_column_names = new_column_names_)\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # stop timer\n",
    "    stop = timeit.default_timer()\n",
    "    \n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) df_products_also_bought"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(119220, 2)\n",
      "Time:  27.285966067000118\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(141780, 2)\n",
      "Time:  56.72587409699918\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(126419, 2)\n",
      "Time:  38.10331394199602\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(85937, 2)\n",
      "Time:  31.628067198005738\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(33847, 2)\n",
      "Time:  12.582625779999944\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(123385, 2)\n",
      "Time:  37.37732017199596\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(661883, 2)\n",
      "Time:  243.20014063400595\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_ = 'df_products_also_bought'\n",
    "for filename in metadata_files_to_read:\n",
    "    \n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df = getDF(filename)\n",
    "    df_transformed = get_dict_embeded_items(df=df,target_var='related', target_key='also_bought')\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # stop timer\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) df_products_also_viewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(38798, 2)\n",
      "Time:  30.600529074996302\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(190555, 2)\n",
      "Time:  54.74302975700266\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(194249, 2)\n",
      "Time:  38.83115368500148\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(138443, 2)\n",
      "Time:  32.687248663998616\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(51741, 2)\n",
      "Time:  11.749239247001242\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(87292, 2)\n",
      "Time:  37.02678551799909\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(960314, 2)\n",
      "Time:  251.81925783900078\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_ = 'df_products_also_viewed'\n",
    "for filename in metadata_files_to_read:\n",
    "    \n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df = getDF(filename)\n",
    "    df_transformed = get_dict_embeded_items(df=df,target_var='related', target_key='also_viewed')\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # stop timer\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5) df_products_bought_together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(81539, 2)\n",
      "Time:  30.269841127999825\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(140898, 2)\n",
      "Time:  55.679200569000386\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(112964, 2)\n",
      "Time:  35.91843018500367\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(102283, 2)\n",
      "Time:  32.43215459200292\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(31305, 2)\n",
      "Time:  12.396068101996207\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(101462, 2)\n",
      "Time:  37.524519144004444\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(572794, 2)\n",
      "Time:  234.1239114429991\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_ = 'df_products_bought_together'\n",
    "for filename in metadata_files_to_read:\n",
    "    \n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df = getDF(filename)\n",
    "    df_transformed = get_dict_embeded_items(df=df,target_var='related', target_key='bought_together')\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # stop timer\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6) df_products_sales_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(204907, 3)\n",
      "Time:  34.98880069000006\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(107648, 3)\n",
      "Time:  54.38227691600332\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(253985, 3)\n",
      "Time:  36.520024053003\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(51334, 3)\n",
      "Time:  32.23155760100053\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(36, 3)\n",
      "Time:  11.269762977004575\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(339012, 3)\n",
      "Time:  37.180118112002674\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(1421649, 3)\n",
      "Time:  283.67257153399987\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_ = 'df_products_sales_rank'\n",
    "for filename in metadata_files_to_read:\n",
    "    \n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df = getDF(filename)\n",
    "    df_transformed = get_df_products_salesrank(df)\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7) df_products_categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanwal/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/indexing.py:362: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[key] = _infer_fill_value(value)\n",
      "/Users/kanwal/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n",
      "/Users/kanwal/miniconda3/envs/py3/lib/python3.6/site-packages/pandas/core/generic.py:1996: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block0_values] [items->['productid', 'categories']]\n",
      "\n",
      "  return pytables.to_hdf(path_or_buf, key, self, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data_in/meta_data/meta_Movies_and_TV.json.gz\n",
      "(208321, 2)\n",
      "Time:  36.145316804002505\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Electronics.json.gz\n",
      "(498196, 2)\n",
      "Time:  72.35126653499901\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Beauty.json.gz\n",
      "(259204, 2)\n",
      "Time:  44.8357321509975\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Tools_and_Home_Improvement.json.gz\n",
      "(269120, 2)\n",
      "Time:  37.002529479999794\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Baby.json.gz\n",
      "(71317, 2)\n",
      "Time:  18.34138311400602\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Cell_Phones_and_Accessories.json.gz\n",
      "(346793, 2)\n",
      "Time:  40.507202704997326\n",
      "\n",
      "\n",
      "./data_in/meta_data/meta_Clothing_Shoes_and_Jewelry.json.gz\n",
      "(1503384, 2)\n",
      "Time:  217.79500212400308\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "key_ = 'df_products_categories'\n",
    "for filename in metadata_files_to_read:\n",
    "    \n",
    "    # start timer\n",
    "    start = timeit.default_timer()\n",
    "\n",
    "    # get data\n",
    "    categoryname = get_category_from_metadata(filename)\n",
    "    df = getDF(filename)\n",
    "    df_transformed = get_df_products_categories(df)\n",
    "    \n",
    "    # write data\n",
    "    output_filepath = './data_out/databases/' + categoryname + '.h5'\n",
    "    df_transformed.to_hdf(output_filepath, key= key_, mode='a', format = 'fixed', data_columns = ['productid'])\n",
    "    \n",
    "    # stop timer\n",
    "    stop = timeit.default_timer()\n",
    "\n",
    "    # print results\n",
    "    print(filename)\n",
    "    print(df_transformed.shape)\n",
    "    print('Time: ', stop - start)  \n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
